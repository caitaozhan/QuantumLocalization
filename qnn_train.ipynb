{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d6521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchquantum as tq\n",
    "import torchquantum.functional as tqf\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import QuantumSensingDataset\n",
    "from qnn import QuantumSensing, QuantumML0, QuantumML1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183963b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n",
      "{'phase': array([4.0597625, 3.9561498, 2.978269 , 2.9022985], dtype=float32), 'label': array(0)}\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "root_dir = 'qml-data/toy/train'\n",
    "train_dataset = QuantumSensingDataset(root_dir)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "root_dir = 'qml-data/toy/test'\n",
    "test_dataset = QuantumSensingDataset(root_dir)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(train_dataset.__len__())\n",
    "print(test_dataset.__len__())\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a67cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "loss=1.5274028778076172\n",
      "loss=1.3250788450241089\n",
      "accuracy=0.25\n",
      "epoch=1\n",
      "loss=1.2785444259643555\n",
      "loss=1.2095234394073486\n",
      "accuracy=0.96\n",
      "epoch=2\n",
      "loss=1.136954426765442\n",
      "loss=0.9982602000236511\n",
      "accuracy=1.0\n",
      "epoch=3\n",
      "loss=1.0841344594955444\n",
      "loss=0.8038815259933472\n",
      "accuracy=1.0\n",
      "epoch=4\n",
      "loss=0.7527194619178772\n",
      "loss=0.6946508288383484\n",
      "accuracy=1.0\n",
      "epoch=5\n",
      "loss=0.6216016411781311\n",
      "loss=0.5849497318267822\n",
      "accuracy=1.0\n",
      "epoch=6\n",
      "loss=0.5228888988494873\n",
      "loss=0.5026627779006958\n",
      "accuracy=1.0\n",
      "epoch=7\n",
      "loss=0.46952539682388306\n",
      "loss=0.4169218838214874\n",
      "accuracy=1.0\n",
      "epoch=8\n",
      "loss=0.40230226516723633\n",
      "loss=0.34280291199684143\n",
      "accuracy=1.0\n",
      "epoch=9\n",
      "loss=0.32562991976737976\n",
      "loss=0.2877598702907562\n",
      "accuracy=1.0\n",
      "epoch=10\n",
      "loss=0.29273465275764465\n",
      "loss=0.21009264886379242\n",
      "accuracy=1.0\n",
      "epoch=11\n",
      "loss=0.2354767918586731\n",
      "loss=0.2052772492170334\n",
      "accuracy=1.0\n",
      "epoch=12\n",
      "loss=0.20772768557071686\n",
      "loss=0.20318329334259033\n",
      "accuracy=1.0\n",
      "epoch=13\n",
      "loss=0.19715078175067902\n",
      "loss=0.16233962774276733\n",
      "accuracy=1.0\n",
      "epoch=14\n",
      "loss=0.1460476964712143\n",
      "loss=0.15280018746852875\n",
      "accuracy=1.0\n",
      "epoch=15\n",
      "loss=0.1455405056476593\n",
      "loss=0.1366134136915207\n",
      "accuracy=1.0\n",
      "epoch=16\n",
      "loss=0.13275109231472015\n",
      "loss=0.12053637206554413\n",
      "accuracy=1.0\n",
      "epoch=17\n",
      "loss=0.11571097373962402\n",
      "loss=0.1134423017501831\n",
      "accuracy=1.0\n",
      "epoch=18\n",
      "loss=0.10681845992803574\n",
      "loss=0.10525335371494293\n",
      "accuracy=1.0\n",
      "epoch=19\n",
      "loss=0.09961938858032227\n",
      "loss=0.1020626574754715\n",
      "accuracy=1.0\n",
      "epoch=20\n",
      "loss=0.08234533667564392\n",
      "loss=0.08594503998756409\n",
      "accuracy=1.0\n",
      "epoch=21\n",
      "loss=0.08327042311429977\n",
      "loss=0.08925390243530273\n",
      "accuracy=1.0\n",
      "epoch=22\n",
      "loss=0.07951129227876663\n",
      "loss=0.08176621049642563\n",
      "accuracy=1.0\n",
      "epoch=23\n",
      "loss=0.07172993570566177\n",
      "loss=0.07856034487485886\n",
      "accuracy=1.0\n",
      "epoch=24\n",
      "loss=0.06573177129030228\n",
      "loss=0.06933040916919708\n",
      "accuracy=1.0\n"
     ]
    }
   ],
   "source": [
    "# the model and training related variables\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "model = QuantumML0(n_wires=4, n_locations=4).to(device)\n",
    "n_epochs = 25\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    print(f'epoch={e}')\n",
    "    model.train()\n",
    "    for t, sample in enumerate(train_dataloader):\n",
    "        thetas = sample['phase']\n",
    "        targets = sample['label'].to(device)\n",
    "        # preparing sensing data\n",
    "        bsz = thetas.shape[0]\n",
    "        n_qubits = thetas.shape[1]\n",
    "        qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "        qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "        qsensing(qstate)\n",
    "        q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "        q_device.reset_states(bsz=bsz)\n",
    "        # the model\n",
    "        outputs = model(q_device, qstate.states)\n",
    "        # compute loss, gradient, optimize, etc...\n",
    "        loss = F.nll_loss(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 10 == 0:\n",
    "            print(f'loss={loss.item()}')\n",
    "    \n",
    "    model.eval()\n",
    "    target_all = []\n",
    "    output_all = []\n",
    "    with torch.no_grad():\n",
    "        for t, sample in enumerate(test_dataloader):\n",
    "            thetas = sample['phase']\n",
    "            targets = sample['label'].to(device)\n",
    "            bsz = thetas.shape[0]\n",
    "            n_qubits = thetas.shape[1]\n",
    "            qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "            qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "            qsensing(qstate)\n",
    "            q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "            q_device.reset_states(bsz=bsz)\n",
    "            # the model\n",
    "            outputs = model(q_device, qstate.states)\n",
    "            target_all.append(targets)\n",
    "            output_all.append(outputs)\n",
    "        target_all = torch.cat(target_all)\n",
    "        output_all = torch.cat(output_all)\n",
    "        \n",
    "#     print(f'target_all = {target_all}')\n",
    "#     print(f'output_all = {output_all}')\n",
    "    _, indices = output_all.topk(1, dim=1)\n",
    "    masks = indices.eq(target_all.view(-1, 1).expand_as(indices))\n",
    "    size = target_all.shape[0]\n",
    "    corrects = masks.sum().item()\n",
    "    accuracy = corrects / size\n",
    "    print(f'accuracy={accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adef768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "loss=1.4952408075332642\n",
      "loss=1.4221601486206055\n",
      "accuracy=0.25\n",
      "epoch=1\n",
      "loss=1.3084717988967896\n",
      "loss=1.3591673374176025\n",
      "accuracy=0.68\n",
      "epoch=2\n",
      "loss=1.25327467918396\n",
      "loss=1.1748526096343994\n",
      "accuracy=1.0\n",
      "epoch=3\n",
      "loss=1.11481773853302\n",
      "loss=1.0419483184814453\n",
      "accuracy=1.0\n",
      "epoch=4\n",
      "loss=0.9796124696731567\n",
      "loss=0.9416905045509338\n",
      "accuracy=1.0\n",
      "epoch=5\n",
      "loss=0.9174097776412964\n",
      "loss=0.8544785976409912\n",
      "accuracy=1.0\n",
      "epoch=6\n",
      "loss=0.8041238188743591\n",
      "loss=0.7262616753578186\n",
      "accuracy=1.0\n",
      "epoch=7\n",
      "loss=0.7357550859451294\n",
      "loss=0.7362036108970642\n",
      "accuracy=1.0\n",
      "epoch=8\n",
      "loss=0.6418341994285583\n",
      "loss=0.6573255658149719\n",
      "accuracy=1.0\n",
      "epoch=9\n",
      "loss=0.599551796913147\n",
      "loss=0.4605522155761719\n",
      "accuracy=1.0\n",
      "epoch=10\n",
      "loss=0.48134204745292664\n",
      "loss=0.46387407183647156\n",
      "accuracy=1.0\n",
      "epoch=11\n",
      "loss=0.46777525544166565\n",
      "loss=0.41137099266052246\n",
      "accuracy=1.0\n",
      "epoch=12\n",
      "loss=0.4301094114780426\n",
      "loss=0.3954290747642517\n",
      "accuracy=1.0\n",
      "epoch=13\n",
      "loss=0.402992308139801\n",
      "loss=0.3316196799278259\n",
      "accuracy=1.0\n",
      "epoch=14\n",
      "loss=0.35607999563217163\n",
      "loss=0.34687718749046326\n",
      "accuracy=1.0\n",
      "epoch=15\n",
      "loss=0.33936676383018494\n",
      "loss=0.3016399145126343\n",
      "accuracy=1.0\n",
      "epoch=16\n",
      "loss=0.30126550793647766\n",
      "loss=0.2513439357280731\n",
      "accuracy=1.0\n",
      "epoch=17\n",
      "loss=0.24857573211193085\n",
      "loss=0.263458251953125\n",
      "accuracy=1.0\n",
      "epoch=18\n",
      "loss=0.25683945417404175\n",
      "loss=0.2343081384897232\n",
      "accuracy=1.0\n",
      "epoch=19\n",
      "loss=0.22144679725170135\n",
      "loss=0.2070292830467224\n",
      "accuracy=1.0\n",
      "epoch=20\n",
      "loss=0.21653498709201813\n",
      "loss=0.19804412126541138\n",
      "accuracy=1.0\n",
      "epoch=21\n",
      "loss=0.20468781888484955\n",
      "loss=0.17156267166137695\n",
      "accuracy=1.0\n",
      "epoch=22\n",
      "loss=0.18234369158744812\n",
      "loss=0.16391518712043762\n",
      "accuracy=1.0\n",
      "epoch=23\n",
      "loss=0.16003507375717163\n",
      "loss=0.16511915624141693\n",
      "accuracy=1.0\n",
      "epoch=24\n",
      "loss=0.1498904824256897\n",
      "loss=0.14483053982257843\n",
      "accuracy=1.0\n"
     ]
    }
   ],
   "source": [
    "# the model and training related variables\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "model = QuantumML1(n_wires=4, n_locations=4).to(device)\n",
    "n_epochs = 25\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    print(f'epoch={e}')\n",
    "    model.train()\n",
    "    for t, sample in enumerate(train_dataloader):\n",
    "        thetas = sample['phase']\n",
    "        targets = sample['label'].to(device)\n",
    "        # preparing sensing data\n",
    "        bsz = thetas.shape[0]\n",
    "        n_qubits = thetas.shape[1]\n",
    "        qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "        qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "        qsensing(qstate)\n",
    "        q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "        q_device.reset_states(bsz=bsz)\n",
    "        # the model\n",
    "        outputs = model(q_device, qstate.states)\n",
    "        # compute loss, gradient, optimize, etc...\n",
    "        loss = F.nll_loss(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 10 == 0:\n",
    "            print(f'loss={loss.item()}')\n",
    "    \n",
    "    model.eval()\n",
    "    target_all = []\n",
    "    output_all = []\n",
    "    with torch.no_grad():\n",
    "        for t, sample in enumerate(test_dataloader):\n",
    "            thetas = sample['phase']\n",
    "            targets = sample['label'].to(device)\n",
    "            bsz = thetas.shape[0]\n",
    "            n_qubits = thetas.shape[1]\n",
    "            qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "            qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "            qsensing(qstate)\n",
    "            q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "            q_device.reset_states(bsz=bsz)\n",
    "            # the model\n",
    "            outputs = model(q_device, qstate.states)\n",
    "            target_all.append(targets)\n",
    "            output_all.append(outputs)\n",
    "        target_all = torch.cat(target_all)\n",
    "        output_all = torch.cat(output_all)\n",
    "        \n",
    "#     print(f'target_all = {target_all}')\n",
    "#     print(f'output_all = {output_all}')\n",
    "    _, indices = output_all.topk(1, dim=1)\n",
    "    masks = indices.eq(target_all.view(-1, 1).expand_as(indices))\n",
    "    size = target_all.shape[0]\n",
    "    corrects = masks.sum().item()\n",
    "    accuracy = corrects / size\n",
    "    print(f'accuracy={accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ded617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
