{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d302f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchquantum as tq\n",
    "import torchquantum.functional as tqf\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import QuantumSensingDataset\n",
    "from qnn import QuantumSensing, QuantumML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37184fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "100\n",
      "{'phase': array([4.0597625, 3.9561498, 2.978269 , 2.9022985], dtype=float32), 'label': array(0)}\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "root_dir = 'qml-data/toy/train'\n",
    "train_dataset = QuantumSensingDataset(root_dir)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "root_dir = 'qml-data/toy/test'\n",
    "test_dataset = QuantumSensingDataset(root_dir)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(train_dataset.__len__())\n",
    "print(test_dataset.__len__())\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed01fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "loss=1.4783298969268799\n",
      "loss=1.341200351715088\n",
      "accuracy=0.48\n",
      "epoch=1\n",
      "loss=1.1503210067749023\n",
      "loss=1.1464542150497437\n",
      "accuracy=0.84\n",
      "epoch=2\n",
      "loss=1.1050156354904175\n",
      "loss=1.0077183246612549\n",
      "accuracy=1.0\n",
      "epoch=3\n",
      "loss=0.9447122812271118\n",
      "loss=0.8660270571708679\n",
      "accuracy=1.0\n",
      "epoch=4\n",
      "loss=0.7749543190002441\n",
      "loss=0.756308913230896\n",
      "accuracy=1.0\n",
      "epoch=5\n",
      "loss=0.6835474371910095\n",
      "loss=0.6683788895606995\n",
      "accuracy=1.0\n",
      "epoch=6\n",
      "loss=0.5853619575500488\n",
      "loss=0.5427542328834534\n",
      "accuracy=1.0\n",
      "epoch=7\n",
      "loss=0.4951237738132477\n",
      "loss=0.47508564591407776\n",
      "accuracy=1.0\n",
      "epoch=8\n",
      "loss=0.45358145236968994\n",
      "loss=0.3992227613925934\n",
      "accuracy=1.0\n",
      "epoch=9\n",
      "loss=0.3552781045436859\n",
      "loss=0.3695710599422455\n",
      "accuracy=1.0\n",
      "epoch=10\n",
      "loss=0.315591424703598\n",
      "loss=0.36177298426628113\n",
      "accuracy=1.0\n",
      "epoch=11\n",
      "loss=0.2917434573173523\n",
      "loss=0.27257809042930603\n",
      "accuracy=1.0\n",
      "epoch=12\n",
      "loss=0.25115787982940674\n",
      "loss=0.2463836371898651\n",
      "accuracy=1.0\n",
      "epoch=13\n",
      "loss=0.24202734231948853\n",
      "loss=0.21259015798568726\n",
      "accuracy=1.0\n",
      "epoch=14\n",
      "loss=0.21787908673286438\n",
      "loss=0.18951384723186493\n",
      "accuracy=1.0\n",
      "epoch=15\n",
      "loss=0.182169571518898\n",
      "loss=0.19166266918182373\n",
      "accuracy=1.0\n",
      "epoch=16\n",
      "loss=0.17927736043930054\n",
      "loss=0.16160514950752258\n",
      "accuracy=1.0\n",
      "epoch=17\n",
      "loss=0.16350288689136505\n",
      "loss=0.1815163642168045\n",
      "accuracy=1.0\n",
      "epoch=18\n",
      "loss=0.16528300940990448\n",
      "loss=0.1233612447977066\n",
      "accuracy=1.0\n",
      "epoch=19\n",
      "loss=0.14576685428619385\n",
      "loss=0.11246290802955627\n",
      "accuracy=1.0\n",
      "epoch=20\n",
      "loss=0.11852215230464935\n",
      "loss=0.12094979733228683\n",
      "accuracy=1.0\n",
      "epoch=21\n",
      "loss=0.12248223274946213\n",
      "loss=0.13681989908218384\n",
      "accuracy=1.0\n",
      "epoch=22\n",
      "loss=0.12099317461252213\n",
      "loss=0.0952092707157135\n",
      "accuracy=1.0\n",
      "epoch=23\n",
      "loss=0.09809339046478271\n",
      "loss=0.09238217771053314\n",
      "accuracy=1.0\n",
      "epoch=24\n",
      "loss=0.1060391366481781\n",
      "loss=0.08380645513534546\n",
      "accuracy=1.0\n"
     ]
    }
   ],
   "source": [
    "# the model and training related variables\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "model = QuantumML(n_wires=4, n_locations=4).to(device)\n",
    "n_epochs = 25\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    print(f'epoch={e}')\n",
    "    model.train()\n",
    "    for t, sample in enumerate(train_dataloader):\n",
    "        thetas = sample['phase']\n",
    "        targets = sample['label'].to(device)\n",
    "        # preparing sensing data\n",
    "        bsz = X.shape[0]\n",
    "        n_qubits = X.shape[1]\n",
    "        qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "        qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "        qsensing(qstate)\n",
    "        q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "        q_device.reset_states(bsz=bsz)\n",
    "        # the model\n",
    "        outputs = model(q_device, qstate.states)\n",
    "        # compute loss, gradient, optimize, etc...\n",
    "        loss = F.nll_loss(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 10 == 0:\n",
    "            print(f'loss={loss.item()}')\n",
    "    \n",
    "    model.eval()\n",
    "    target_all = []\n",
    "    output_all = []\n",
    "    with torch.no_grad():\n",
    "        for t, sample in enumerate(test_dataloader):\n",
    "            thetas = sample['phase']\n",
    "            targets = sample['label'].to(device)\n",
    "            bsz = X.shape[0]\n",
    "            n_qubits = X.shape[1]\n",
    "            qsensing = QuantumSensing(n_qubits=n_qubits, list_of_thetas=thetas, device=device)\n",
    "            qstate = tq.QuantumState(n_wires=n_qubits, bsz=bsz)\n",
    "            qsensing(qstate)\n",
    "            q_device = tq.QuantumDevice(n_wires=n_qubits)\n",
    "            q_device.reset_states(bsz=bsz)\n",
    "            # the model\n",
    "            outputs = model(q_device, qstate.states)\n",
    "            target_all.append(targets)\n",
    "            output_all.append(outputs)\n",
    "        target_all = torch.cat(target_all)\n",
    "        output_all = torch.cat(output_all)\n",
    "        \n",
    "#     print(f'target_all = {target_all}')\n",
    "#     print(f'output_all = {output_all}')\n",
    "    _, indices = output_all.topk(1, dim=1)\n",
    "    masks = indices.eq(target_all.view(-1, 1).expand_as(indices))\n",
    "    size = target_all.shape[0]\n",
    "    corrects = masks.sum().item()\n",
    "    accuracy = corrects / size\n",
    "    print(f'accuracy={accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
